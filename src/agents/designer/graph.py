"""
Base chat agent implementation that provides common chat functionality
for agents that need interactive conversation capabilities.
"""

import os
import logging
from abc import abstractmethod
from typing import Optional
from langchain_core.runnables import RunnableConfig

from langchain_core.messages import AIMessage, SystemMessage, HumanMessage
from langgraph.graph import StateGraph, START, END
from langgraph.types import Command, interrupt
from langgraph.prebuilt import create_react_agent

from ..base import BaseAgent, BaseState
from .prompt import NOTEHELPER_SYSTEM_PROMPT, SUMMARY_SYSTEM_PROMPT
from .config import ThreadConfiguration
from .schema import NoteHelperState
from src.config.manager import AgentConfig, MultiAgentConfig
from src.utils.input_processor import create_multimodal_message
from .callback import SummaryNodeCallback

logger = logging.getLogger(__name__)


class BaseNoteHelperAgent(BaseAgent):
    """
    Base chat agent that provides common interactive conversation functionality.
    This class can be inherited by specific agents like tutor, solver, etc.
    """

    name = "base_notehelper_agent"
    description = "Base notehelper agent that provides interactive conversation capabilities."

    def __init__(self, agent_config: AgentConfig):
        """Initialize the notehelper agent.

        Args:
            agent_config: Configuration object containing model parameters and tools.
        """
        super().__init__(agent_config)
        logger.info(f"{self.name} chat agent initialized successfully")
        self._wrap_llm_with_callback()

    def _load_system_prompt(self):
        """Load the system prompt for the chat agent."""
        self._system_prompt = {
            "chat_node": NOTEHELPER_SYSTEM_PROMPT,
            "summary_node": SUMMARY_SYSTEM_PROMPT,
        }
        self._user_prompt = {
            "chat_node": open(os.path.join(os.path.dirname(__file__), "prompt/chat_prompt.txt"), "r").read(),
            "summary_node": open(os.path.join(os.path.dirname(__file__), "prompt/summary_prompt.txt"), "r").read(),
        }

    def _wrap_llm_with_callback(self):
        """ç»™ self._llm åŠ ä¸Š callbackï¼Œè¿”å›æ–°çš„ llm å®ä¾‹"""
        cb = SummaryNodeCallback(node_name="summary_node")
        # å…³é”®ï¼šLangChain çš„ Runnable æ”¯æŒ callbacks å‚æ•°
        # æˆ‘ä»¬ç›´æ¥æŠŠ callback ç»‘å®šåˆ° llm ä¸Šï¼Œåé¢æ‰€æœ‰ invoke/ainvoke éƒ½ä¼šè‡ªåŠ¨å¸¦
        self._llm = self._llm.with_config(callbacks=[cb])
  
    async def init_context_node(self, state: NoteHelperState, config=None):
        """æŠŠç”¨æˆ·ç¬¬ä¸€æ¬¡ä¼ è¿›æ¥çš„è¦æ±‚å›ºåŒ–åˆ° state"""
        logger.info("[init_context] è¿›å…¥")
        # å‰ç«¯/æµ‹è¯•è„šæœ¬å¯ä»¥æŠŠè¦æ±‚å†™åœ¨ state é‡Œï¼Œè¿™é‡Œåªåšä¿åº•
        if not state.user_specified_format.requirements:
            state.user_specified_format.requirements = "é»˜è®¤ï¼šç”Ÿæˆè¯¦ç»† markdown è¯¾å ‚ç¬”è®°"
        return {"user_specified_format": state.user_specified_format}

    async def summary_node(self, state: NoteHelperState, config=None):
        """çœŸæ­£çš„æ‘˜è¦èŠ‚ç‚¹ï¼Œåªæ¥å— (state,config)"""
        logger.info("[summary_node] è¿›å…¥")
        from langchain_core.messages import SystemMessage, HumanMessage

        sys_msg = SystemMessage(content=self._system_prompt["summary_node"])
        interaction_history_str = "\n".join(
            f"{i+1}. {s}" for i, s in enumerate(state.interaction_history)
        )
        user_prompt = (
            open(os.path.join(os.path.dirname(__file__), "prompt/summary_prompt.txt"))
            .read()
            .format(
                history_summary="\n".join(state.history_summaries),
                current_full_asr=state.currimulate_asr_result
                + state.current_asr_chunk,
                user_specific_format=state.user_specified_format.model_dump_json(),
                interaction_history=interaction_history_str,
                industry_domain=state.industry_domain or "",
            )
        )
        # logger.info(f"[summary_node] ğŸ“ prompt: {user_prompt}")
        logger.info(f"[summary_node] ğŸ“ current_full_asr: {state.currimulate_asr_result + state.current_asr_chunk}")
        full_prompt = self._system_prompt["summary_node"]+user_prompt
        logger.info(f"[summary_node] prompt: {full_prompt}")
        response = await self._llm.ainvoke([sys_msg, HumanMessage(content=user_prompt)])

        logger.info(f"[summary_node] ğŸ“ current_final_notes: {state.final_notes + response.content}")
        # ç´¯åŠ  ASR å¹¶ä¿å­˜æ–°æ‘˜è¦
        return {
            "currimulate_asr_result": state.current_asr_chunk,
            "history_summaries": [response.content],
            "final_notes": state.final_notes + "\n\n" + response.content,
            "current_asr_chunk": "",   # æ¶ˆè´¹å®Œæ¸…ç©º
        }
        
    async def wait_node(self, state: NoteHelperState, config = None):
        """ä¼šé˜»å¡ï¼Œç›´åˆ°å¤–éƒ¨è°ƒç”¨è€…é€šè¿‡ .ainvoke ä¼ å…¥æ–° ASR"""
        logger.info("[wait_node] è¿›å…¥")
        # å¦‚æœå½“å‰å·²ç»æœ‰ current_asr_chunkï¼ˆå¤–éƒ¨åˆšå–‚çš„ï¼‰ï¼Œç›´æ¥æ”¾è¡Œ
        logger.info(f"[wait_node] state.current_asr_chunk: {state.current_asr_chunk}")
        logger.info(f"[wait_node] state.current_message: {state.current_message}")
        
        if state.current_asr_chunk.strip():
            return Command(goto="summary_node")
        if state.current_message.strip():
            return Command(goto="chat_node")
        if state.asr_end:
            return Command(goto=END)
        # å¦åˆ™ interrupt ç­‰å¾…
        logger.info("[wait_node] å³å°† interrupt â€¦")
        # logger.info(f"[wait_node] payload: {payload}")
        payload = interrupt("ç­‰å¾…è¾“å…¥")      # è¿™é‡Œä¼šæŠ›ç‰¹æ®Šå¼‚å¸¸ï¼ŒæŠŠæ§åˆ¶æƒäº¤å›ç»™ç”¨æˆ·
        # payload = payload.value
        
        if "current_asr_chunk" in payload or "industry_domain" in payload:
            updates = {}
            if "current_asr_chunk" in payload:
                updates["current_asr_chunk"] = payload.pop("current_asr_chunk")
            if "industry_domain" in payload:
                updates["industry_domain"] = payload.pop("industry_domain")
            return Command(goto="summary_node", update=updates)
        elif "current_message" in payload:
            return Command(goto="chat_node", update={"current_message": payload.pop("current_message")})
        elif "asr_end" in payload:
            return Command(goto=END, update={"asr_end": payload.pop("asr_end")})
        # else:
        #     return Command(goto="wait_node")
    
        # logger.info(f"ASR è¾“å…¥: {msg}")
        # å¤–éƒ¨è°ƒç”¨è€…ä¼šæŠŠ ASR å†™åœ¨ state.current_asr_chunk é‡Œ
        # return Command(goto="summary_node", update={"current_asr_chunk": asr})
        # return Command(goto="router_node")
    
    async def chat_node(
        self, state: NoteHelperState, config: Optional[RunnableConfig] = None
    ):
        """Handle chat conversation with tools support.

        Args:
            state: The current agent state.
            config: Optional configuration for the node.

        Returns:
            Command: Command to continue to human_chat_node.
        """
        logger.info("[chat_node] è¿›å…¥")
        # Create react agent with tools for interactive conversation
        if self._tools:
            react_agent = create_react_agent(
                name=self.name,
                model=self._llm,
                tools=self._tools,
            )

            # Prepare messages with system context
            system_message = SystemMessage(
                content=self._system_prompt["chat_node"]
            )
            messages = [
                system_message
            ] + [
                HumanMessage(
                    content=self._user_prompt["chat_node"].format(
                        current_full_asr=state.currimulate_asr_result,
                        current_full_notes=state.final_notes,
                        user_question=state.current_message,
                    )
                )
            ]

            # Get response from react agent
            response = await react_agent.ainvoke({"messages": messages})
            last_message = response["messages"][-1]

            interaction = f"ç”¨æˆ·æé—®ï¼š{state.current_message}"
            return {
                "messages": [last_message],
                "interaction_history": [interaction],
                "current_message": "",
            }
        else:
            # Fallback to simple LLM without tools
            system_message = SystemMessage(content=self._system_prompt["chat_node"])

            messages = [
                system_message
            ] + [
                HumanMessage(
                    content=self._user_prompt["chat_node"].format(
                        current_full_asr=state.currimulate_asr_result,
                        current_full_notes=state.final_notes,
                        user_question=state.current_message,
                    )
                )
            ]

            response = await self._llm.ainvoke(messages)
            logger.info(f"chat agent response: {response.content}")

            interaction = f"ç”¨æˆ·æé—®ï¼š{state.current_message}"
            return {
                "messages": [response],
                "interaction_history": [interaction],
                "current_message": "",
            }

    # async def router_node(self, state: NoteHelperState, config=None) -> Command:
    #     """ç®€å•æ¼”ç¤ºï¼šå¦‚æœå¤–éƒ¨ä¸å†å–‚ ASR å°±ç»“æŸ"""
    #     logger.info("[router_node] è¿›å…¥")
    #     logger.info(f"[router_node] state.current_message: {state.current_message}")
    #     # logger.info(f"[router_node] state.asr_end: {state.asr_end}")
        
    #     if state.current_asr_chunk:
    #         logger.info("[router_node] è¿›å…¥ ASR")
    #         return Command(goto="summary_node")
    #     if state.current_message:
    #         logger.info("[router_node] è¿›å…¥ chat")
    #         return Command(goto="chat_node")
    #     if state.asr_end:
    #         logger.info("[router_node] è¿›å…¥ END")
    #         return Command(goto=END)
        
    #     logger.info("[router_node] è¿›å…¥ wait")
    #     return Command(goto="wait_node")

    def build_graph(self):
        from langgraph.graph import StateGraph, START, END
        graph = StateGraph(NoteHelperState)
        graph.add_node("init_context", self.init_context_node)
        graph.add_node("wait_node", self.wait_node)
        graph.add_node("chat_node", self.chat_node)
        # graph.add_node("router_node", self.router_node)
        graph.add_node("summary_node", self.summary_node)
        # graph.add_node("should_continue", self.should_continue)

        graph.add_edge(START, "init_context")
        graph.add_edge("init_context", "wait_node")
        graph.add_edge("summary_node", "wait_node")
        graph.add_edge("chat_node", "wait_node")
        # graph.add_edge("wait_node", "router_node")
        return graph
    
    
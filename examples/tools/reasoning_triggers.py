"""
Test file using LLM to call tools from triggers.py
"""

import asyncio
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage, SystemMessage
from src.infra.tools.triggers import think_tool, plan_tool, task_done


async def test_llm_tool_calls():
    print("=" * 60)
    print("TESTING LLM TOOL CALLS")
    print("=" * 60)

    # Initialize LLM with tools
    llm = init_chat_model(model="gpt-4.1-mini", temperature=0)

    # Bind tools to LLM
    tools = [think_tool, plan_tool, task_done]
    llm_with_tools = llm.bind_tools(tools)

    print(f"âœ… LLM initialized: {llm.model_name}")
    print(f"âœ… Tools bound: {[tool.name for tool in tools]}")

    # Test 1: LLM calls think_tool
    print("\n" + "=" * 40)
    print("TEST 1: LLM calls think_tool")
    print("=" * 40)

    messages1 = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæ¨ç†æ™ºèƒ½ä½“ã€‚ä½ æœ‰think_toolã€plan_toolå’Œtask_doneå·¥å…·ã€‚"),
        HumanMessage(content="è¯·æ€è€ƒä¸€ä¸‹å¦‚ä½•åˆ¶å®šä¸€ä¸ªå­¦ä¹ Pythonçš„è®¡åˆ’"),
    ]

    response1 = await llm_with_tools.ainvoke(messages1)
    print(f"LLM Response: {response1.content}")
    print(f"Tool calls: {response1.tool_calls}")

    if response1.tool_calls:
        for tool_call in response1.tool_calls:
            print(f"\nğŸ”§ Tool Call Details:")
            print(f"   Name: {tool_call['name']}")
            print(f"   ID: {tool_call['id']}")
            print(f"   Args: {tool_call['args']}")
            print(f"   Args type: {type(tool_call['args'])}")

    # Test 2: LLM calls plan_tool
    print("\n" + "=" * 40)
    print("TEST 2: LLM calls plan_tool")
    print("=" * 40)

    messages2 = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªæ¨ç†æ™ºèƒ½ä½“ã€‚ä½ æœ‰think_toolã€plan_toolå’Œtask_doneå·¥å…·ã€‚"),
        HumanMessage(content="è¯·åˆ¶å®šä¸€ä¸ªå…·ä½“çš„3ä¸ªæœˆPythonå­¦ä¹ è®¡åˆ’ï¼Œåˆ†è§£æˆå…·ä½“æ­¥éª¤"),
    ]

    response2 = await llm_with_tools.ainvoke(messages2)
    print(f"LLM Response: {response2.content}")
    print(f"Tool calls: {response2.tool_calls}")

    if response2.tool_calls:
        for tool_call in response2.tool_calls:
            print(f"\nğŸ”§ Tool Call Details:")
            print(f"   Name: {tool_call['name']}")
            print(f"   ID: {tool_call['id']}")
            print(f"   Args: {tool_call['args']}")
            print(f"   Args type: {type(tool_call['args'])}")

            # Test how we would extract plan data in the agent
            if tool_call["name"] == "plan_tool":
                thought = tool_call["args"].get("thought", "")
                steps = tool_call["args"].get("steps", [])
                plan_data = {"thought": thought, "steps": steps}

                print(f"\nğŸ“‹ Plan Data Processing:")
                print(f"   Thought: '{thought}'")
                print(f"   Steps: {steps}")
                print(f"   Steps type: {type(steps)}")
                print(f"   Plan_data: {plan_data}")

                print(f"\nğŸ“ Individual Steps:")
                for i, step in enumerate(steps):
                    print(f"   Step {i}: '{step}' ({type(step)})")

    # Test 3: LLM calls task_done
    print("\n" + "=" * 40)
    print("TEST 3: LLM calls task_done")
    print("=" * 40)

    messages3 = [
        SystemMessage(
            content="ä½ æ˜¯ä¸€ä¸ªæ¨ç†æ™ºèƒ½ä½“ã€‚ä½ æœ‰think_toolã€plan_toolå’Œtask_doneå·¥å…·ã€‚å½“ä½ å®Œæˆä¸€ä¸ªä»»åŠ¡æ­¥éª¤æ—¶ï¼Œè¯·ä½¿ç”¨task_doneå·¥å…·ã€‚"
        ),
        HumanMessage(content="æˆ‘åˆšå®Œæˆäº†PythonåŸºç¡€è¯­æ³•çš„å­¦ä¹ ï¼Œè¯·ç¡®è®¤è¿™ä¸ªæ­¥éª¤å®Œæˆ"),
    ]

    response3 = await llm_with_tools.ainvoke(messages3)
    print(f"LLM Response: {response3.content}")
    print(f"Tool calls: {response3.tool_calls}")

    if response3.tool_calls:
        for tool_call in response3.tool_calls:
            print(f"\nğŸ”§ Tool Call Details:")
            print(f"   Name: {tool_call['name']}")
            print(f"   ID: {tool_call['id']}")
            print(f"   Args: {tool_call['args']}")
            print(f"   Args type: {type(tool_call['args'])}")


if __name__ == "__main__":
    asyncio.run(test_llm_tool_calls())
